csv:
  baseFolder: ${CSV_BASE_FOLDER:./.data}
  archive:
    enabled: true
  zip:
    enabled: true

certs:
  folder: ${CERTS_FOLDER:./.certs}
  password: ${CERTS_PASSWORD:changeit}

server:
  port: ${SERVER_PORT:8080}

spring:
  datasource:
    url: ${SPRING_DATASOURCE_URL:jdbc:postgresql://localhost:5432/scheduler}
    username: ${SPRING_DATASOURCE_USERNAME:scheduler}
    password: ${SPRING_DATASOURCE_PASSWORD:scheduler}
  jpa:
    open-in-view: false
    hibernate:
      ddl-auto: validate
    properties:
      hibernate.jdbc.time_zone: UTC
      hibernate.jdbc.lob.non_contextual_creation: true
      # If you use a custom schema, uncomment:
      # hibernate.default_schema: scheduler_app
  flyway:
    enabled: true
    # If DB already has data/schema, baseline to avoid errors on first run:
    # baseline-on-migrate: true
    # If you use a custom schema, keep Flyway/Hibernate/Quartz consistent:
    # schemas: [scheduler_app]
    # default-schema: scheduler_app
  quartz:
    job-store-type: jdbc
    jdbc:
      # Let Flyway manage Quartz tables; don't auto-create:
      initialize-schema: never
    properties:
      org.quartz.scheduler.instanceName: scheduler-platform
      org.quartz.scheduler.instanceId: AUTO
      org.quartz.scheduler.skipUpdateCheck: true

      org.quartz.threadPool.threadCount: 10

      org.quartz.jobStore.class: org.springframework.scheduling.quartz.LocalDataSourceJobStore
      org.quartz.jobStore.driverDelegateClass: org.quartz.impl.jdbcjobstore.PostgreSQLDelegate
      org.quartz.jobStore.misfireThreshold: 60000
      # Enable if running >1 app instance:
      # org.quartz.jobStore.isClustered: true
      # org.quartz.jobStore.clusterCheckinInterval: 15000
      # Use a prefix and (optionally) schema:
      # org.quartz.jobStore.tablePrefix: QRTZ_
      # or, with schema:
      # org.quartz.jobStore.tablePrefix: scheduler_app.QRTZ_
      # Recommended on Postgres to reduce deadlocks under load:
      # org.quartz.jobStore.acquireTriggersWithinLock: true

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      probes:
        enabled: true
      show-details: when_authorized

springdoc:
  swagger-ui:
    path: /swagger-ui
  api-docs:
    path: /v3/api-docs

logging:
  level:
    org.springframework: INFO

ingest:
  csv:
    employees:
      defaultStatus: IN_PROGRESS
      enabled: true
      fileFolder: ${csv.baseFolder}/ingest/employees
      processedFolder: ${csv.baseFolder}/ingest/employees/processed
      fileNamePrefix: employees-
      tableName: employee 
      columnMapping:
        person_id: id
        full_name: name
        years: age
  archive:
    enabled: true
  zip:
    enabled: true

extract:
  csv:
    employees:
      readyToExtarctStatus: IN_PROGRESS
      extractedStatus: EXTRACTED
      enabled: true
      fileFolder: ${csv.baseFolder}/extract/employees
      processedFolder: ${csv.baseFolder}/extract/employees/processed
      fileNamePrefix: employees-
      tableName: employee 
      columnMapping:
        person_id: id
        full_name: name
        years: age
  archive:
    enabled: true
  zip:
    enabled: true

transfer:
    rest:
      enabled: false
      accessTokenUrl: ${TRANSFER_REST_ACCESS_TOKEN_URL:https://api.example.com/accessToken}
      username: ${TRANSFER_REST_ACCESS_TOKEN_USERNAME:apiuser}
      password: ${TRANSFER_REST_ACCESS_TOKEN_PASSWORD:apipass}
      cert:
        path: ${TRANSFER_REST_ACCESS_TOKEN_CERT_PATH:${certs.folder}/client.p12}
        password: ${TRANSFER_REST_ACCESS_TOKEN_CERT_PASSWORD:${certs.password}}
    sftp:
      enabled: false
      host: ${TRANSFER_SFTP_HOST:localhost}
      port: ${TRANSFER_SFTP_PORT:22}
      username: ${TRANSFER_SFTP_USERNAME:sftpuser}
      password: ${TRANSFER_SFTP_PASSWORD:sftppass}
      remoteDirectory: /uploads
